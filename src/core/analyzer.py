"""
ç«å“åˆ†æå™¨ï¼ˆæ ¸å¿ƒç¼–æ’æ¨¡å—ï¼‰
"""
import json
from typing import List, Dict, Optional
from pathlib import Path
from datetime import datetime

from src.config import config
from src.discovery.discoverer import CompetitorDiscoverer
from src.crawler.url_crawler import URLCrawler
from src.analysis.extractor import InformationExtractor, ComparisonAnalyzer
from src.database import Competitor, DataSource, RawContent, ParsedData, SessionLocal


class CompetitorAnalyzer:
    """ç«å“åˆ†æå™¨ï¼ˆä¸»å…¥å£ï¼‰"""
    
    def __init__(self):
        self.discoverer = CompetitorDiscoverer()
        self.crawler = URLCrawler()
        self.extractor = InformationExtractor()
        self.comparator = ComparisonAnalyzer()
    
    def analyze_from_topic(
        self,
        topic: str,
        market: str = "ä¸­å›½",
        target_count: int = 3,
        depth: str = "standard",
        auto_crawl: bool = True
    ) -> Dict:
        """
        ä»ä¸»é¢˜å¼€å§‹å®Œæ•´åˆ†æï¼ˆæ™ºèƒ½å‘ç°æ¨¡å¼ï¼‰
        
        Args:
            topic: è°ƒç ”ä¸»é¢˜
            market: ç›®æ ‡å¸‚åœº
            target_count: ç«å“æ•°é‡
            depth: æœç´¢æ·±åº¦
            auto_crawl: æ˜¯å¦è‡ªåŠ¨å¼€å§‹çˆ¬å–
        
        Returns:
            åˆ†æç»“æœ
        """
        print("\n" + "="*80)
        print(f"ğŸš€ è‡ªåŠ¨åŒ–ç«å“åˆ†æ: {topic}")
        print("="*80)
        
        # é˜¶æ®µ1: æ™ºèƒ½å‘ç°
        print("\nğŸ“ é˜¶æ®µ 1/4: æ™ºèƒ½æ•°æ®æºå‘ç°")
        discovery_result = self.discoverer.discover(
            topic=topic,
            market=market,
            target_count=target_count,
            depth=depth
        )
        
        competitors = discovery_result["competitors"]
        
        if not auto_crawl:
            print("\nâ¸ï¸  è‡ªåŠ¨çˆ¬å–å·²ç¦ç”¨ï¼Œè¯·æ‰‹åŠ¨ç¡®è®¤åç»§ç»­")
            return discovery_result
        
        # é˜¶æ®µ2: æ•°æ®é‡‡é›†
        print("\nğŸ“ é˜¶æ®µ 2/4: æ•°æ®é‡‡é›†")
        crawl_results = self._crawl_competitors(competitors)
        
        # é˜¶æ®µ3: ä¿¡æ¯æå–
        print("\nğŸ“ é˜¶æ®µ 3/4: AI ä¿¡æ¯æå–")
        extracted_data = self._extract_information(crawl_results)
        
        # é˜¶æ®µ4: ç”ŸæˆæŠ¥å‘Š
        print("\nğŸ“ é˜¶æ®µ 4/4: ç”Ÿæˆåˆ†ææŠ¥å‘Š")
        report_path = self._generate_report(topic, extracted_data)
        
        print("\n" + "="*80)
        print("âœ… åˆ†æå®Œæˆï¼")
        print(f"ğŸ“Š æŠ¥å‘Šè·¯å¾„: {report_path}")
        print("="*80 + "\n")
        
        return {
            "topic": topic,
            "competitors": competitors,
            "crawl_results": crawl_results,
            "extracted_data": extracted_data,
            "report_path": report_path
        }
    
    def analyze_from_config(self, config_file: str) -> Dict:
        """ä»é…ç½®æ–‡ä»¶åˆ†æï¼ˆæ‰‹åŠ¨é…ç½®æ¨¡å¼ï¼‰"""
        # TODO: å®ç°é…ç½®æ–‡ä»¶è§£æ
        pass
    
    def _crawl_competitors(self, competitors: List[Dict]) -> List[Dict]:
        """çˆ¬å–ç«å“æ•°æ®"""
        results = []
        
        for i, comp in enumerate(competitors, 1):
            comp_name = comp["name"]
            print(f"\n[{i}/{len(competitors)}] çˆ¬å– {comp_name}")
            
            # è·å–æ•°æ®æº
            data_sources = comp.get("data_sources", [])
            if not data_sources:
                print(f"  âš ï¸  æ²¡æœ‰æ•°æ®æºï¼Œè·³è¿‡")
                continue
            
            # çˆ¬å–å‰3ä¸ªé«˜ä¼˜å…ˆçº§æ•°æ®æº
            urls_to_crawl = [
                ds["url"] for ds in sorted(
                    data_sources, 
                    key=lambda x: x["priority"]
                )[:3]
            ]
            
            crawl_results = self.crawler.batch_crawl(urls_to_crawl, comp_name)
            
            results.append({
                "competitor": comp_name,
                "confidence": comp.get("confidence", 0.8),
                "crawl_results": crawl_results
            })
        
        return results
    
    def _extract_information(self, crawl_results: List[Dict]) -> List[Dict]:
        """æå–ä¿¡æ¯"""
        extracted = []
        
        for comp_data in crawl_results:
            comp_name = comp_data["competitor"]
            print(f"\nğŸ” åˆ†æ {comp_name}")
            
            # åˆå¹¶æ‰€æœ‰çˆ¬å–å†…å®¹
            all_content = ""
            for result in comp_data["crawl_results"]:
                if result.get("success"):
                    all_content += result.get("content", "") + "\n\n"
            
            if not all_content:
                print("  âš ï¸  æ²¡æœ‰æœ‰æ•ˆå†…å®¹ï¼Œè·³è¿‡")
                extracted.append({
                    "competitor": comp_name,
                    "data": {}
                })
                continue
            
            # æå–ä¿¡æ¯
            data = self.extractor.extract_all(all_content, comp_name)
            
            # ç”Ÿæˆ SWOT
            print("  ğŸ“Š ç”Ÿæˆ SWOT åˆ†æ...")
            swot = self.comparator.generate_swot(data)
            data["swot"] = swot
            
            extracted.append({
                "competitor": comp_name,
                "confidence": comp_data.get("confidence", 0.8),
                "data": data
            })
        
        return extracted
    
    def _generate_report(self, topic: str, extracted_data: List[Dict]) -> str:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_topic = topic.replace(" ", "_")[:30]
        report_name = f"{safe_topic}_{timestamp}"
        report_dir = config.REPORTS_DIR / report_name
        report_dir.mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆ Markdown æŠ¥å‘Š
        report_path = report_dir / "report.md"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(self._render_markdown_report(topic, extracted_data))
        
        # ä¿å­˜ JSON æ•°æ®
        json_path = report_dir / "data.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(extracted_data, f, ensure_ascii=False, indent=2)
        
        print(f"  ğŸ“„ Markdown: {report_path}")
        print(f"  ğŸ“Š JSON: {json_path}")
        
        return str(report_path)
    
    def _render_markdown_report(self, topic: str, extracted_data: List[Dict]) -> str:
        """æ¸²æŸ“ Markdown æŠ¥å‘Š"""
        md = f"""# {topic} - ç«å“åˆ†ææŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}  
**ç«å“æ•°é‡**: {len(extracted_data)}  
**ç”Ÿæˆå·¥å…·**: è‡ªåŠ¨åŒ–ç«å“åˆ†æå·¥å…· v0.1

---

## æ‰§è¡Œæ‘˜è¦

æœ¬æŠ¥å‘Šé€šè¿‡æ™ºèƒ½æ•°æ®æºå‘ç°ã€è‡ªåŠ¨åŒ–é‡‡é›†å’Œ AI åˆ†æï¼Œå¯¹ {len(extracted_data)} ä¸ª {topic} ç«å“è¿›è¡Œäº†å…¨é¢åˆ†æã€‚

---

## ç«å“æ¦‚è§ˆ

"""
        
        # ç«å“åˆ—è¡¨
        for i, comp in enumerate(extracted_data, 1):
            comp_name = comp["competitor"]
            confidence = comp.get("confidence", 0) * 100
            product_info = comp.get("data", {}).get("product_info", {})
            
            md += f"""### {i}. {comp_name}

- **ç½®ä¿¡åº¦**: {confidence:.0f}%
- **å…¬å¸**: {product_info.get('company', 'æœªçŸ¥')}
- **å®šä½**: {product_info.get('tagline', 'æœªçŸ¥')}
- **ç®€ä»‹**: {product_info.get('description', 'æœªçŸ¥')}

"""
        
        # è¯¦ç»†åˆ†æ
        md += "\n---\n\n## è¯¦ç»†åˆ†æ\n\n"
        
        for i, comp in enumerate(extracted_data, 1):
            comp_name = comp["competitor"]
            data = comp.get("data", {})
            
            md += f"### {i}. {comp_name}\n\n"
            
            # æ ¸å¿ƒåŠŸèƒ½
            md += "#### æ ¸å¿ƒåŠŸèƒ½\n\n"
            features = data.get("features", {}).get("core_features", [])
            if features:
                for feat in features[:5]:
                    unique = "ğŸŒŸ " if feat.get("unique") else ""
                    md += f"- {unique}**{feat.get('name', '')}**: {feat.get('description', '')}\n"
            else:
                md += "*æš‚æ— åŠŸèƒ½ä¿¡æ¯*\n"
            md += "\n"
            
            # ä»·æ ¼ç­–ç•¥
            md += "#### ä»·æ ¼ç­–ç•¥\n\n"
            pricing = data.get("pricing", {})
            if pricing and pricing.get("price_tiers"):
                md += f"**æ¨¡å¼**: {pricing.get('pricing_model', 'æœªçŸ¥')}\n\n"
                for tier in pricing.get("price_tiers", []):
                    price = tier.get("price", 0)
                    currency = tier.get("currency", "CNY")
                    cycle = tier.get("billing_cycle", "")
                    md += f"- **{tier.get('name', '')}**: {currency} {price}/{cycle}\n"
            else:
                md += "*æš‚æ— ä»·æ ¼ä¿¡æ¯*\n"
            md += "\n"
            
            # SWOT åˆ†æ
            md += "#### SWOT åˆ†æ\n\n"
            swot = data.get("swot", {})
            if swot:
                md += "**ä¼˜åŠ¿ (Strengths)**:\n"
                for s in swot.get("strengths", [])[:3]:
                    md += f"- {s.get('point', '')} ({s.get('impact', '')}å½±å“)\n"
                md += "\n"
                
                md += "**åŠ£åŠ¿ (Weaknesses)**:\n"
                for w in swot.get("weaknesses", [])[:3]:
                    md += f"- {w.get('point', '')} ({w.get('impact', '')}å½±å“)\n"
                md += "\n"
                
                md += "**æœºä¼š (Opportunities)**:\n"
                for o in swot.get("opportunities", [])[:2]:
                    md += f"- {o.get('point', '')}\n"
                md += "\n"
                
                md += "**å¨èƒ (Threats)**:\n"
                for t in swot.get("threats", [])[:2]:
                    md += f"- {t.get('point', '')}\n"
                md += "\n"
            
            md += "---\n\n"
        
        # æ€»ç»“
        md += """## æ€»ç»“ä¸å»ºè®®

### å¸‚åœºæ ¼å±€

[åŸºäºä»¥ä¸Šåˆ†æï¼Œæ€»ç»“å¸‚åœºç«äº‰æ ¼å±€]

### æˆ˜ç•¥å»ºè®®

1. **äº§å“ç­–ç•¥**: 
2. **å®šä»·ç­–ç•¥**: 
3. **è¥é”€ç­–ç•¥**: 

---

*æœ¬æŠ¥å‘Šç”± AI è‡ªåŠ¨ç”Ÿæˆï¼Œå»ºè®®ç»“åˆäººå·¥åˆ¤æ–­è¿›è¡Œå†³ç­–*
"""
        
        return md
